{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Final Project Notebook\nThis notebook implements the project pipeline in the intended execution order: **data \u2192 targets \u2192 model \u2192 loss/metrics \u2192 training \u2192 evaluation**. Each section below adds the corresponding building blocks, starting from data loading and augmentations and ending with training and evaluation placeholders.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Imports & Seeds"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import random\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nimport solt\nimport solt.transforms as slt\nfrom tqdm.auto import tqdm\n\nSEED = 42\n\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\ncv2.ocl.setUseOpenCL(False)\ncv2.setNumThreads(0)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Data Loading"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "class KneeSegmentationDataset(Dataset):\n    \"\"\"Slice-wise dataset with paired SOLT transforms.\"\"\"\n\n    def __init__(self, df: pd.DataFrame, transforms: solt.Stream | None):\n        self.dataset = df.reset_index(drop=True)\n        self.trf = transforms\n\n    def __len__(self) -> int:\n        return len(self.dataset)\n\n    def __getitem__(self, idx: int) -> dict:\n        entry = self.dataset.iloc[idx]\n        img = cv2.imread(str(entry.img), cv2.IMREAD_COLOR)\n        mask = cv2.imread(str(entry.segmask), cv2.IMREAD_GRAYSCALE)\n        if img is None or mask is None:\n            raise FileNotFoundError(f\"Missing image/mask for index {idx}\")\n\n        if self.trf is not None:\n            res = self.trf({\"image\": img, \"mask\": mask}, return_torch=False)\n            img, mask = res.data\n\n        img = img.astype(np.float32) / 255.0\n        mask = mask.astype(np.int64)\n\n        img_t = torch.from_numpy(img).permute(2, 0, 1)\n        mask_t = torch.from_numpy(mask).unsqueeze(0)\n\n        return {\"image\": img_t, \"mask\": mask_t}\n\n\nclass KneeSegmentationDatasetVol(Dataset):\n    \"\"\"Volume-wise dataset that groups slices by scan.\"\"\"\n\n    def __init__(self, df: pd.DataFrame, transforms: solt.Stream | None, load_mask: bool = True):\n        super().__init__()\n        self.df = df\n        self.trf = transforms\n        self.load_mask = load_mask\n\n        self.scans = []\n        for _, g in self.df.groupby([\"ID\", \"SIDE\", \"VISIT\"]):\n            g = g.sort_values(by=\"slice_idx\").reset_index(drop=True)\n            self.scans.append(g)\n\n    def __len__(self) -> int:\n        return len(self.scans)\n\n    def __getitem__(self, index: int) -> dict:\n        return self.load_volume(self.scans[index], self.trf, load_mask=self.load_mask)\n\n    @staticmethod\n    def _to_chw_tensor(img: np.ndarray | torch.Tensor) -> torch.Tensor:\n        if isinstance(img, np.ndarray):\n            tensor = torch.from_numpy(img)\n            if tensor.dim() == 3 and tensor.shape[-1] in (1, 3):\n                tensor = tensor.permute(2, 0, 1)\n            tensor = tensor.float() / 255.0\n            return tensor\n\n        if torch.is_tensor(img):\n            tensor = img.float()\n            if tensor.dim() == 3 and tensor.shape[-1] in (1, 3):\n                tensor = tensor.permute(2, 0, 1)\n            if tensor.max() > 1.0:\n                tensor = tensor / 255.0\n            return tensor\n\n        raise TypeError(\"Unsupported image type for volume loading\")\n\n    @staticmethod\n    def _to_hw_long(mask: np.ndarray | torch.Tensor) -> torch.Tensor:\n        if isinstance(mask, np.ndarray):\n            tensor = torch.from_numpy(mask)\n        elif torch.is_tensor(mask):\n            tensor = mask\n        else:\n            raise TypeError(\"Unsupported mask type for volume loading\")\n\n        if tensor.dim() == 3 and tensor.size(0) == 1:\n            tensor = tensor.squeeze(0)\n        return tensor.long()\n\n    @staticmethod\n    def load_volume(vol_df: pd.DataFrame, transform: solt.Stream | None, load_mask: bool = True) -> dict:\n        images, masks = [], []\n        for _, entry in vol_df.iterrows():\n            img = cv2.imread(str(entry.img), cv2.IMREAD_COLOR)\n            if img is None:\n                raise FileNotFoundError(f\"Missing image: {entry.img}\")\n            images.append(img)\n\n            if load_mask:\n                mask = cv2.imread(str(entry.segmask), cv2.IMREAD_GRAYSCALE)\n                if mask is None:\n                    raise FileNotFoundError(f\"Missing mask: {entry.segmask}\")\n                masks.append(mask)\n\n        if transform is not None:\n            if load_mask:\n                res = transform({\"images\": images, \"masks\": masks})\n            else:\n                res = transform({\"images\": images})\n            images = res[\"images\"]\n            if load_mask:\n                masks = res[\"masks\"]\n\n        scan = torch.stack([KneeSegmentationDatasetVol._to_chw_tensor(img) for img in images], dim=0)\n        if load_mask:\n            mask = torch.stack([KneeSegmentationDatasetVol._to_hw_long(m) for m in masks], dim=0)\n        else:\n            mask = None\n\n        return {\"scan\": scan, \"mask\": mask}\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Augmentation"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "train_trf = solt.Stream([\n    slt.Resize((256, 256)),\n    slt.Flip(p=0.5, axis=1),\n    slt.Crop((224, 224), crop_mode=\"r\"),\n    slt.GammaCorrection(gamma_range=0.1, p=1),\n])\n\nval_trf = solt.Stream([\n    slt.Resize((256, 256)),\n])\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Config"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "@dataclass\nclass Cfg:\n    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    in_channels: int = 3\n    num_classes: int = 2\n\n    dataset_train_cls = KneeSegmentationDataset\n    dataset_val_cls = KneeSegmentationDataset\n\n    optimizer_cls = torch.optim.AdamW\n    loss_fn = torch.nn.CrossEntropyLoss()\n\n    lr: float = 1e-3\n    wd: float = 5e-5\n    num_epochs: int = 1\n    n_workers: int = 0\n    train_bs: int = 2\n    val_bs: int = 2\n\n    lr_drop_milestones: list[int] = None\n    class_names: list[str] = None\n\n    train_trf: solt.Stream | None = train_trf\n    val_trf: solt.Stream | None = val_trf\n\n    def __post_init__(self):\n        if self.lr_drop_milestones is None:\n            self.lr_drop_milestones = [30]\n        if self.class_names is None:\n            self.class_names = [\"BG\", \"FG\"]\n        self.num_classes = len(self.class_names)\n\n\nclass CfgHighRes(Cfg):\n    train_trf = solt.Stream([\n        slt.Flip(p=0.5, axis=1),\n        slt.Crop((320, 320), crop_mode=\"r\"),\n        slt.GammaCorrection(gamma_range=0.1, p=1),\n    ])\n\n    val_trf = solt.Stream([])\n\n\nclass CfgVol(Cfg):\n    dataset_val_cls = KneeSegmentationDatasetVol\n    val_bs = 1\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Trainer"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "class SimpleSegmentationNet(nn.Module):\n    def __init__(self, in_channels: int, num_classes: int):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(in_channels, 16, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, num_classes, kernel_size=1),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.net(x)\n\n\nclass BaseTrainer:\n    def __init__(self, train_df: pd.DataFrame, val_df: pd.DataFrame, cfg: Cfg):\n        self.train_df = train_df\n        self.val_df = val_df\n        self.cfg = cfg\n\n        self.train_loader = None\n        self.val_loader = None\n        self.loss_fn = None\n        self.optimizer = None\n        self.model = None\n\n    def init_model(self):\n        raise NotImplementedError\n\n    def init_run(self):\n        self.init_model()\n\n        train_ds = self.cfg.dataset_train_cls(self.train_df, self.cfg.train_trf)\n        val_ds = self.cfg.dataset_val_cls(self.val_df, self.cfg.val_trf)\n\n        self.train_loader = DataLoader(\n            train_ds,\n            batch_size=self.cfg.train_bs,\n            shuffle=True,\n            num_workers=self.cfg.n_workers,\n            pin_memory=True,\n        )\n        self.val_loader = DataLoader(\n            val_ds,\n            batch_size=self.cfg.val_bs,\n            shuffle=False,\n            num_workers=self.cfg.n_workers,\n            pin_memory=True,\n        )\n\n        self.optimizer = self.cfg.optimizer_cls(\n            self.model.parameters(),\n            lr=self.cfg.lr,\n            weight_decay=self.cfg.wd,\n        )\n        self.loss_fn = self.cfg.loss_fn\n\n    def adjust_lr(self):\n        if self.cfg.lr_drop_milestones and self.epoch in self.cfg.lr_drop_milestones:\n            for param_group in self.optimizer.param_groups:\n                param_group[\"lr\"] *= 0.1\n\n    def run(self, n_epochs: int | None = None):\n        self.init_run()\n        if n_epochs is None:\n            n_epochs = self.cfg.num_epochs\n\n        for self.epoch in range(n_epochs):\n            self.model.train()\n            train_loss = self.train_epoch()\n            self.model.eval()\n            val_out = self.val_epoch()\n            self.post_val_hook(train_loss, val_out)\n\n    def train_epoch(self):\n        pbar = tqdm(self.train_loader, desc=f\"[{self.epoch}] Train\")\n        running_loss = 0.0\n        self.adjust_lr()\n\n        for i, batch in enumerate(pbar):\n            self.optimizer.zero_grad()\n            loss, _ = self.pass_batch(batch)\n            loss.backward()\n            self.optimizer.step()\n\n            running_loss += float(loss.item())\n            pbar.set_postfix({\"loss\": running_loss / (i + 1)})\n\n        return running_loss / max(1, len(self.train_loader))\n\n    def val_epoch(self):\n        raise NotImplementedError\n\n    def post_val_hook(self, train_loss, val_out):\n        print(\"=\" * 50)\n        print(f\"[{self.epoch}] --> Train loss: {train_loss:.4f}\")\n        print(f\"[{self.epoch}] --> Val loss: {val_out['val_loss']:.4f}\")\n        print(\"=\" * 50)\n\n    def pass_batch(self, batch):\n        img = batch[\"image\"].to(self.cfg.device)\n        mask = batch[\"mask\"].to(self.cfg.device)\n\n        logits = self.model(img)\n        target = mask.squeeze(1).long()\n        loss = self.loss_fn(logits, target)\n        return loss, logits\n\n\nclass SegmentationTrainer2D(BaseTrainer):\n    def init_model(self):\n        self.model = SimpleSegmentationNet(\n            in_channels=self.cfg.in_channels,\n            num_classes=self.cfg.num_classes,\n        ).to(self.cfg.device)\n\n    @torch.no_grad()\n    def val_epoch(self):\n        running_loss = 0.0\n        pbar = tqdm(self.val_loader, desc=f\"[{self.epoch}] Val\", leave=False)\n        for i, batch in enumerate(pbar):\n            loss, _ = self.pass_batch(batch)\n            running_loss += float(loss.item())\n            pbar.set_postfix({\"loss\": running_loss / (i + 1)})\n        return {\"val_loss\": running_loss / max(1, len(self.val_loader))}\n\n\nclass SegmentationTrainer3D(SegmentationTrainer2D):\n    def pass_eval_batch(self, batch, compute_loss: bool = False):\n        scan = batch[\"scan\"].to(self.cfg.device)\n        target = batch.get(\"mask\")\n        if target is not None:\n            target = target.to(self.cfg.device)\n\n        batch_size, n_slices, _, height, width = scan.shape\n        logits_vol = torch.zeros(\n            batch_size, self.cfg.num_classes, n_slices, height, width,\n            device=self.cfg.device,\n        )\n\n        total_loss = 0.0\n        for slice_idx in range(n_slices):\n            x_s = scan[:, slice_idx, ...]\n            logits_s = self.model(x_s)\n            logits_vol[:, :, slice_idx, :, :] = logits_s\n\n            if compute_loss and target is not None:\n                y_s = target[:, slice_idx, ...]\n                loss_s = self.loss_fn(logits_s, y_s)\n                total_loss += float(loss_s.item())\n\n        loss_i = total_loss / max(1, n_slices) if compute_loss else None\n        return loss_i, logits_vol, target\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Sanity Check"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "tmp_root = Path(\"/tmp/seg_sanity\")\ntmp_root.mkdir(parents=True, exist_ok=True)\n\nsamples = []\nfor idx in range(4):\n    img = (np.random.rand(256, 256, 3) * 255).astype(np.uint8)\n    mask = (np.random.rand(256, 256) > 0.5).astype(np.uint8)\n    img_path = tmp_root / f\"img_{idx}.png\"\n    mask_path = tmp_root / f\"mask_{idx}.png\"\n    cv2.imwrite(str(img_path), img)\n    cv2.imwrite(str(mask_path), mask * 255)\n    samples.append({\n        \"img\": img_path,\n        \"segmask\": mask_path,\n        \"ID\": 0,\n        \"SIDE\": \"L\",\n        \"VISIT\": 0,\n        \"slice_idx\": idx,\n    })\n\ndf = pd.DataFrame(samples)\nds = KneeSegmentationDataset(df, val_trf)\nsample = ds[0]\nprint(\"Image shape:\", sample[\"image\"].shape)\nprint(\"Mask shape:\", sample[\"mask\"].shape)\n\nmodel = SimpleSegmentationNet(in_channels=3, num_classes=2).to(Cfg().device)\nwith torch.no_grad():\n    logits = model(sample[\"image\"].unsqueeze(0).to(Cfg().device))\nprint(\"Logits shape:\", logits.shape)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Training Loop"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "cfg = Cfg()\ntrainer = SegmentationTrainer2D(df, df, cfg)\ntrainer.run(n_epochs=1)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Evaluation / Visualization"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# TODO: Add prediction visualization and slice-wise evaluation helpers.\n# Example: overlay predictions on input slices or render scan-level summaries.\n",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}