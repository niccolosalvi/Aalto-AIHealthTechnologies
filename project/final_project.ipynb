{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Project Notebook\n",
        "\n",
        "This notebook implements incremental subtasks for the knee cartilage segmentation project.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subtask 1: Recreate slice caching and data indexing\n",
        "\n",
        "**Goal:** Convert 3D volumes into cached 2D slices and build a slice-level index.\n",
        "\n",
        "**Files modified/created:** `project/final_project.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Basic imports\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import cv2\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Fixing one of the most annoying \"features\" of opencv\n",
        "cv2.ocl.setUseOpenCL(False)\n",
        "cv2.setNumThreads(0)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configuration\n",
        "# Update base_dir to point to the extracted dataset directory in Colab/Drive.\n",
        "# Expected filename pattern: <PATIENT>_<VISIT>_<SIDE>_img.nii(.gz)\n",
        "base_dir = Path(\"/content/knee_dataset\")\n",
        "\n",
        "# Cache directory for 2D slices\n",
        "dataset_local_dir = Path(\"/content/dataset_slices\")\n",
        "images_dir = dataset_local_dir / \"images\"\n",
        "masks_dir = dataset_local_dir / \"masks\"\n",
        "images_dir.mkdir(parents=True, exist_ok=True)\n",
        "masks_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Index path for cached slices\n",
        "slice_index_path = dataset_local_dir / \"slice_index.csv\"\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def vis_slice(img, lp=0, hp=99.9):\n",
        "    # Normalize a slice to uint8 for PNG storage.\n",
        "    img_float = img.astype(np.float32)\n",
        "    low = np.percentile(img_float, lp)\n",
        "    high = np.percentile(img_float, hp)\n",
        "    img_norm = (img_float - low) / (high - low)\n",
        "    img_norm = np.clip(img_norm, 0, 1)\n",
        "    return (img_norm * 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "def orient_slice(slice_2d):\n",
        "    # Match the orientation used in assignment 3 visualizations.\n",
        "    slice_2d = np.rot90(slice_2d, k=3)\n",
        "    slice_2d = np.fliplr(slice_2d)\n",
        "    return slice_2d\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build volume-level dataframe from the dataset directory\n",
        "volume_rows = []\n",
        "for img_path in base_dir.glob(\"*_img.nii*\"):\n",
        "    patient, visit, side, _ = img_path.name.split(\"_\")\n",
        "    volume_rows.append({\n",
        "        \"img\": img_path,\n",
        "        \"segmask\": img_path.parent / img_path.name.replace(\"_img\", \"_mask\"),\n",
        "        \"ID\": patient,\n",
        "        \"VISIT\": visit,\n",
        "        \"SIDE\": side,\n",
        "    })\n",
        "\n",
        "vol_df = pd.DataFrame(volume_rows)\n",
        "vol_df.head()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Slice caching + indexing (skip if cache already exists)\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "import multiprocessing as mp\n",
        "\n",
        "\n",
        "def process_volume(row_dict, images_dir, masks_dir):\n",
        "    row = pd.Series(row_dict)\n",
        "    img_nii = nib.load(row.img)\n",
        "    mask_nii = nib.load(row.segmask)\n",
        "\n",
        "    img_data = img_nii.get_fdata()\n",
        "    mask_data = mask_nii.get_fdata()\n",
        "\n",
        "    records = []\n",
        "    for slice_idx in range(img_data.shape[0]):\n",
        "        img_slice = orient_slice(vis_slice(img_data[slice_idx, :, :]))\n",
        "        mask_slice = orient_slice(mask_data[slice_idx, :, :])\n",
        "\n",
        "        img_name = f\"{row.ID}_{row.VISIT}_{row.SIDE}_slice{slice_idx:03d}.png\"\n",
        "        mask_name = f\"{row.ID}_{row.VISIT}_{row.SIDE}_slice{slice_idx:03d}.png\"\n",
        "        img_path = images_dir / img_name\n",
        "        mask_path = masks_dir / mask_name\n",
        "\n",
        "        cv2.imwrite(str(img_path), img_slice)\n",
        "        cv2.imwrite(str(mask_path), mask_slice.astype(np.uint8))\n",
        "\n",
        "        records.append({\n",
        "            \"ID\": row.ID,\n",
        "            \"VISIT\": row.VISIT,\n",
        "            \"SIDE\": row.SIDE,\n",
        "            \"slice_idx\": slice_idx,\n",
        "            \"img\": str(img_path),\n",
        "            \"segmask\": str(mask_path),\n",
        "        })\n",
        "\n",
        "    return records\n",
        "\n",
        "\n",
        "if slice_index_path.exists():\n",
        "    slice_ds = pd.read_csv(slice_index_path)\n",
        "else:\n",
        "    rows = vol_df.to_dict(orient=\"records\")\n",
        "    all_records = []\n",
        "    max_workers = min(4, mp.cpu_count())\n",
        "\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = [executor.submit(process_volume, row, images_dir, masks_dir) for row in rows]\n",
        "        for fut in as_completed(futures):\n",
        "            all_records.extend(fut.result())\n",
        "\n",
        "    slice_ds = pd.DataFrame(all_records)\n",
        "    slice_ds.to_csv(slice_index_path, index=False)\n",
        "\n",
        "slice_ds.head()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sanity check 1\n",
        "Verify cached files exist and the index is populated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "assert len(slice_ds) > 0, \"Slice index is empty.\"\n",
        "\n",
        "example = slice_ds.iloc[0]\n",
        "assert Path(example.img).exists(), \"Cached image not found.\"\n",
        "assert Path(example.segmask).exists(), \"Cached mask not found.\"\n",
        "\n",
        "print(f\"Cached {len(slice_ds)} slices.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subtask 2: Patient-aware split logic\n",
        "\n",
        "**Goal:** Create train/val/test splits without patient leakage.\n",
        "\n",
        "**Files modified/created:** `project/final_project.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def make_patient_splits(slice_df, test_size=0.2, val_size=0.2, seed=SEED):\n",
        "    patients = slice_df[\"ID\"].astype(str) + \"_\" + slice_df[\"SIDE\"]\n",
        "    unique_patients = patients.unique()\n",
        "\n",
        "    trainval_patients, test_patients = train_test_split(\n",
        "        unique_patients,\n",
        "        test_size=test_size,\n",
        "        random_state=seed,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    train_patients, val_patients = train_test_split(\n",
        "        trainval_patients,\n",
        "        test_size=val_size,\n",
        "        random_state=seed,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    train_df = slice_df[patients.isin(train_patients)].reset_index(drop=True)\n",
        "    val_df = slice_df[patients.isin(val_patients)].reset_index(drop=True)\n",
        "    test_df = slice_df[patients.isin(test_patients)].reset_index(drop=True)\n",
        "\n",
        "    return train_df, val_df, test_df, set(train_patients), set(val_patients), set(test_patients)\n",
        "\n",
        "\n",
        "train_df, val_df, test_df, train_patients, val_patients, test_patients = make_patient_splits(slice_ds)\n",
        "\n",
        "print(f\"Train patients: {len(train_patients)} \u2192 {len(train_df)} slices\")\n",
        "print(f\"Val   patients: {len(val_patients)} \u2192 {len(val_df)} slices\")\n",
        "print(f\"Test  patients: {len(test_patients)} \u2192 {len(test_df)} slices\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sanity check 2\n",
        "Ensure no patient overlap across splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "assert train_patients.isdisjoint(val_patients), \"Train/val patient leakage detected.\"\n",
        "assert train_patients.isdisjoint(test_patients), \"Train/test patient leakage detected.\"\n",
        "assert val_patients.isdisjoint(test_patients), \"Val/test patient leakage detected.\"\n",
        "\n",
        "print(\"Patient splits are disjoint.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subtask 3: Minimal batch sanity check\n",
        "\n",
        "**Goal:** Load a batch and confirm shapes + mask alignment.\n",
        "\n",
        "**Files modified/created:** `project/final_project.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class SliceDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = cv2.imread(row.img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(row.segmask, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0\n",
        "        mask = torch.from_numpy(mask).long()\n",
        "        return {\"image\": img, \"mask\": mask}\n",
        "\n",
        "\n",
        "train_ds = SliceDataset(train_df)\n",
        "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0)\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "images = batch[\"image\"]\n",
        "masks = batch[\"mask\"]\n",
        "\n",
        "print(\"Image batch shape:\", images.shape)\n",
        "print(\"Mask batch shape:\", masks.shape)\n",
        "assert images.shape[-2:] == masks.shape[-2:], \"Image/mask spatial dimensions do not match.\"\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sanity check 3\n",
        "Visualize a single image/mask pair for alignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "img_np = images[0].permute(1, 2, 0).numpy()\n",
        "mask_np = masks[0].numpy()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
        "axes[0].imshow(img_np)\n",
        "axes[0].set_title(\"Image\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(mask_np, cmap=\"viridis\")\n",
        "axes[1].set_title(\"Mask\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}