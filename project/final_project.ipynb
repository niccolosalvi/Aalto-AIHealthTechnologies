{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Project Notebook\n",
        "This notebook implements the project pipeline in the intended execution order: **data \u2192 targets \u2192 model \u2192 loss/metrics \u2192 training \u2192 evaluation**. Each section below adds the corresponding building blocks, starting from data loading and augmentations and ending with training and evaluation placeholders.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports & Seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import solt\n",
        "import solt.transforms as slt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "cv2.ocl.setUseOpenCL(False)\n",
        "cv2.setNumThreads(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class KneeSegmentationDataset(Dataset):\n",
        "    \"\"\"Slice-wise dataset with paired SOLT transforms.\"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, transforms: solt.Stream | None):\n",
        "        self.dataset = df.reset_index(drop=True)\n",
        "        self.trf = transforms\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> dict:\n",
        "        entry = self.dataset.iloc[idx]\n",
        "        img = cv2.imread(str(entry.img), cv2.IMREAD_COLOR)\n",
        "        mask = cv2.imread(str(entry.segmask), cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None or mask is None:\n",
        "            raise FileNotFoundError(f\"Missing image/mask for index {idx}\")\n",
        "\n",
        "        if self.trf is not None:\n",
        "            res = self.trf({\"image\": img, \"mask\": mask}, return_torch=False)\n",
        "            img, mask = res.data\n",
        "\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        mask = mask.astype(np.int64)\n",
        "\n",
        "        img_t = torch.from_numpy(img).permute(2, 0, 1)\n",
        "        mask_t = torch.from_numpy(mask).unsqueeze(0)\n",
        "\n",
        "        return {\"image\": img_t, \"mask\": mask_t}\n",
        "\n",
        "\n",
        "class KneeSegmentationDatasetVol(Dataset):\n",
        "    \"\"\"Volume-wise dataset that groups slices by scan.\"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, transforms: solt.Stream | None, load_mask: bool = True):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.trf = transforms\n",
        "        self.load_mask = load_mask\n",
        "\n",
        "        self.scans = []\n",
        "        for _, g in self.df.groupby([\"ID\", \"SIDE\", \"VISIT\"]):\n",
        "            g = g.sort_values(by=\"slice_idx\").reset_index(drop=True)\n",
        "            self.scans.append(g)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.scans)\n",
        "\n",
        "    def __getitem__(self, index: int) -> dict:\n",
        "        return self.load_volume(self.scans[index], self.trf, load_mask=self.load_mask)\n",
        "\n",
        "    @staticmethod\n",
        "    def _to_chw_tensor(img: np.ndarray | torch.Tensor) -> torch.Tensor:\n",
        "        if isinstance(img, np.ndarray):\n",
        "            tensor = torch.from_numpy(img)\n",
        "            if tensor.dim() == 3 and tensor.shape[-1] in (1, 3):\n",
        "                tensor = tensor.permute(2, 0, 1)\n",
        "            tensor = tensor.float() / 255.0\n",
        "            return tensor\n",
        "\n",
        "        if torch.is_tensor(img):\n",
        "            tensor = img.float()\n",
        "            if tensor.dim() == 3 and tensor.shape[-1] in (1, 3):\n",
        "                tensor = tensor.permute(2, 0, 1)\n",
        "            if tensor.max() > 1.0:\n",
        "                tensor = tensor / 255.0\n",
        "            return tensor\n",
        "\n",
        "        raise TypeError(\"Unsupported image type for volume loading\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _to_hw_long(mask: np.ndarray | torch.Tensor) -> torch.Tensor:\n",
        "        if isinstance(mask, np.ndarray):\n",
        "            tensor = torch.from_numpy(mask)\n",
        "        elif torch.is_tensor(mask):\n",
        "            tensor = mask\n",
        "        else:\n",
        "            raise TypeError(\"Unsupported mask type for volume loading\")\n",
        "\n",
        "        if tensor.dim() == 3 and tensor.size(0) == 1:\n",
        "            tensor = tensor.squeeze(0)\n",
        "        return tensor.long()\n",
        "\n",
        "    @staticmethod\n",
        "    def load_volume(vol_df: pd.DataFrame, transform: solt.Stream | None, load_mask: bool = True) -> dict:\n",
        "        images, masks = [], []\n",
        "        for _, entry in vol_df.iterrows():\n",
        "            img = cv2.imread(str(entry.img), cv2.IMREAD_COLOR)\n",
        "            if img is None:\n",
        "                raise FileNotFoundError(f\"Missing image: {entry.img}\")\n",
        "            images.append(img)\n",
        "\n",
        "            if load_mask:\n",
        "                mask = cv2.imread(str(entry.segmask), cv2.IMREAD_GRAYSCALE)\n",
        "                if mask is None:\n",
        "                    raise FileNotFoundError(f\"Missing mask: {entry.segmask}\")\n",
        "                masks.append(mask)\n",
        "\n",
        "        if transform is not None:\n",
        "            if load_mask:\n",
        "                res = transform({\"images\": images, \"masks\": masks})\n",
        "            else:\n",
        "                res = transform({\"images\": images})\n",
        "            images = res[\"images\"]\n",
        "            if load_mask:\n",
        "                masks = res[\"masks\"]\n",
        "\n",
        "        scan = torch.stack([KneeSegmentationDatasetVol._to_chw_tensor(img) for img in images], dim=0)\n",
        "        if load_mask:\n",
        "            mask = torch.stack([KneeSegmentationDatasetVol._to_hw_long(m) for m in masks], dim=0)\n",
        "        else:\n",
        "            mask = None\n",
        "\n",
        "        return {\"scan\": scan, \"mask\": mask}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_trf = solt.Stream([\n",
        "    slt.Resize((256, 256)),\n",
        "    slt.Flip(p=0.5, axis=1),\n",
        "    slt.Crop((224, 224), crop_mode=\"r\"),\n",
        "    slt.GammaCorrection(gamma_range=0.1, p=1),\n",
        "])\n",
        "\n",
        "val_trf = solt.Stream([\n",
        "    slt.Resize((256, 256)),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Cfg:\n",
        "    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    in_channels: int = 3\n",
        "    num_classes: int = 2\n",
        "\n",
        "    dataset_train_cls = KneeSegmentationDataset\n",
        "    dataset_val_cls = KneeSegmentationDataset\n",
        "\n",
        "    optimizer_cls = torch.optim.AdamW\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    lr: float = 1e-3\n",
        "    wd: float = 5e-5\n",
        "    num_epochs: int = 1\n",
        "    n_workers: int = 0\n",
        "    train_bs: int = 2\n",
        "    val_bs: int = 2\n",
        "\n",
        "    lr_drop_milestones: list[int] = None\n",
        "    class_names: list[str] = None\n",
        "\n",
        "    train_trf: solt.Stream | None = train_trf\n",
        "    val_trf: solt.Stream | None = val_trf\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.lr_drop_milestones is None:\n",
        "            self.lr_drop_milestones = [30]\n",
        "        if self.class_names is None:\n",
        "            self.class_names = [\"BG\", \"FG\"]\n",
        "        self.num_classes = len(self.class_names)\n",
        "\n",
        "\n",
        "class CfgHighRes(Cfg):\n",
        "    train_trf = solt.Stream([\n",
        "        slt.Flip(p=0.5, axis=1),\n",
        "        slt.Crop((320, 320), crop_mode=\"r\"),\n",
        "        slt.GammaCorrection(gamma_range=0.1, p=1),\n",
        "    ])\n",
        "\n",
        "    val_trf = solt.Stream([])\n",
        "\n",
        "\n",
        "class CfgVol(Cfg):\n",
        "    dataset_val_cls = KneeSegmentationDatasetVol\n",
        "    val_bs = 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtask: Define INR regression model\n",
        "This subtask introduces a minimal coordinate-based INR MLP that outputs a single continuous value per coordinate, without classification activations.\n",
        "\n",
        "**Files to modify/create:**\n",
        "- `project/final_project.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class INRMLP(nn.Module):\n",
        "    \"\"\"Minimal coordinate-based INR for scalar regression.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int = 2,\n",
        "        hidden_features: int = 128,\n",
        "        hidden_layers: int = 4,\n",
        "        out_features: int = 1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        layers = [nn.Linear(in_features, hidden_features), nn.ReLU(inplace=True)]\n",
        "        for _ in range(hidden_layers - 1):\n",
        "            layers.append(nn.Linear(hidden_features, hidden_features))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        layers.append(nn.Linear(hidden_features, out_features))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, coords: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            coords: (..., 2) tensor of normalized (x, y) coordinates.\n",
        "        Returns:\n",
        "            (...,) tensor of scalar predictions per coordinate.\n",
        "        \"\"\"\n",
        "        flat_coords = coords.view(-1, coords.shape[-1])\n",
        "        out = self.net(flat_coords)\n",
        "        return out.view(*coords.shape[:-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleSegmentationNet(nn.Module):\n",
        "    def __init__(self, in_channels: int, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, num_classes, kernel_size=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class BaseTrainer:\n",
        "    def __init__(self, train_df: pd.DataFrame, val_df: pd.DataFrame, cfg: Cfg):\n",
        "        self.train_df = train_df\n",
        "        self.val_df = val_df\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.train_loader = None\n",
        "        self.val_loader = None\n",
        "        self.loss_fn = None\n",
        "        self.optimizer = None\n",
        "        self.model = None\n",
        "\n",
        "    def init_model(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def init_run(self):\n",
        "        self.init_model()\n",
        "\n",
        "        train_ds = self.cfg.dataset_train_cls(self.train_df, self.cfg.train_trf)\n",
        "        val_ds = self.cfg.dataset_val_cls(self.val_df, self.cfg.val_trf)\n",
        "\n",
        "        self.train_loader = DataLoader(\n",
        "            train_ds,\n",
        "            batch_size=self.cfg.train_bs,\n",
        "            shuffle=True,\n",
        "            num_workers=self.cfg.n_workers,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "        self.val_loader = DataLoader(\n",
        "            val_ds,\n",
        "            batch_size=self.cfg.val_bs,\n",
        "            shuffle=False,\n",
        "            num_workers=self.cfg.n_workers,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "\n",
        "        self.optimizer = self.cfg.optimizer_cls(\n",
        "            self.model.parameters(),\n",
        "            lr=self.cfg.lr,\n",
        "            weight_decay=self.cfg.wd,\n",
        "        )\n",
        "        self.loss_fn = self.cfg.loss_fn\n",
        "\n",
        "    def adjust_lr(self):\n",
        "        if self.cfg.lr_drop_milestones and self.epoch in self.cfg.lr_drop_milestones:\n",
        "            for param_group in self.optimizer.param_groups:\n",
        "                param_group[\"lr\"] *= 0.1\n",
        "\n",
        "    def run(self, n_epochs: int | None = None):\n",
        "        self.init_run()\n",
        "        if n_epochs is None:\n",
        "            n_epochs = self.cfg.num_epochs\n",
        "\n",
        "        history = []\n",
        "        for self.epoch in range(n_epochs):\n",
        "            self.model.train()\n",
        "            train_loss = self.train_epoch()\n",
        "            self.model.eval()\n",
        "            val_out = self.val_epoch()\n",
        "            self.post_val_hook(train_loss, val_out)\n",
        "\n",
        "            history.append({\n",
        "                \"epoch\": self.epoch,\n",
        "                \"train_loss\": float(train_loss),\n",
        "                **val_out,\n",
        "            })\n",
        "        return history\n",
        "\n",
        "    def train_epoch(self):\n",
        "        pbar = tqdm(self.train_loader, desc=f\"[{self.epoch}] Train\")\n",
        "        running_loss = 0.0\n",
        "        self.adjust_lr()\n",
        "\n",
        "        for i, batch in enumerate(pbar):\n",
        "            self.optimizer.zero_grad()\n",
        "            loss, _ = self.pass_batch(batch)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += float(loss.item())\n",
        "            pbar.set_postfix({\"loss\": running_loss / (i + 1)})\n",
        "\n",
        "        return running_loss / max(1, len(self.train_loader))\n",
        "\n",
        "    def val_epoch(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def post_val_hook(self, train_loss, val_out):\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"[{self.epoch}] --> Train loss: {train_loss:.4f}\")\n",
        "        print(f\"[{self.epoch}] --> Val loss: {val_out['val_loss']:.4f}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "    def pass_batch(self, batch):\n",
        "        img = batch[\"image\"].to(self.cfg.device)\n",
        "        mask = batch[\"mask\"].to(self.cfg.device)\n",
        "\n",
        "        logits = self.model(img)\n",
        "        target = mask.squeeze(1).long()\n",
        "        loss = self.loss_fn(logits, target)\n",
        "        return loss, logits\n",
        "\n",
        "\n",
        "class SegmentationTrainer2D(BaseTrainer):\n",
        "    def init_model(self):\n",
        "        self.model = SimpleSegmentationNet(\n",
        "            in_channels=self.cfg.in_channels,\n",
        "            num_classes=self.cfg.num_classes,\n",
        "        ).to(self.cfg.device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def val_epoch(self):\n",
        "        running_loss = 0.0\n",
        "        pbar = tqdm(self.val_loader, desc=f\"[{self.epoch}] Val\", leave=False)\n",
        "        for i, batch in enumerate(pbar):\n",
        "            loss, _ = self.pass_batch(batch)\n",
        "            running_loss += float(loss.item())\n",
        "            pbar.set_postfix({\"loss\": running_loss / (i + 1)})\n",
        "        return {\"val_loss\": running_loss / max(1, len(self.val_loader))}\n",
        "\n",
        "\n",
        "class SegmentationTrainer3D(SegmentationTrainer2D):\n",
        "    def pass_eval_batch(self, batch, compute_loss: bool = False):\n",
        "        scan = batch[\"scan\"].to(self.cfg.device)\n",
        "        target = batch.get(\"mask\")\n",
        "        if target is not None:\n",
        "            target = target.to(self.cfg.device)\n",
        "\n",
        "        batch_size, n_slices, _, height, width = scan.shape\n",
        "        logits_vol = torch.zeros(\n",
        "            batch_size, self.cfg.num_classes, n_slices, height, width,\n",
        "            device=self.cfg.device,\n",
        "        )\n",
        "\n",
        "        total_loss = 0.0\n",
        "        for slice_idx in range(n_slices):\n",
        "            x_s = scan[:, slice_idx, ...]\n",
        "            logits_s = self.model(x_s)\n",
        "            logits_vol[:, :, slice_idx, :, :] = logits_s\n",
        "\n",
        "            if compute_loss and target is not None:\n",
        "                y_s = target[:, slice_idx, ...]\n",
        "                loss_s = self.loss_fn(logits_s, y_s)\n",
        "                total_loss += float(loss_s.item())\n",
        "\n",
        "        loss_i = total_loss / max(1, n_slices) if compute_loss else None\n",
        "        return loss_i, logits_vol, target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sanity Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# INR forward-pass sanity check\n",
        "coords = torch.rand(2, 8, 2) * 2 - 1  # (batch, points, xy) in [-1, 1]\n",
        "inr = INRMLP(in_features=2, hidden_features=64, hidden_layers=3, out_features=1).to(Cfg().device)\n",
        "with torch.no_grad():\n",
        "    preds = inr(coords.to(Cfg().device))\n",
        "print(\"Coords shape:\", coords.shape)\n",
        "print(\"Preds shape:\", preds.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp_root = Path(\"/tmp/seg_sanity\")\n",
        "tmp_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "samples = []\n",
        "for idx in range(4):\n",
        "    img = (np.random.rand(256, 256, 3) * 255).astype(np.uint8)\n",
        "    mask = (np.random.rand(256, 256) > 0.5).astype(np.uint8)\n",
        "    img_path = tmp_root / f\"img_{idx}.png\"\n",
        "    mask_path = tmp_root / f\"mask_{idx}.png\"\n",
        "    cv2.imwrite(str(img_path), img)\n",
        "    cv2.imwrite(str(mask_path), mask * 255)\n",
        "    samples.append({\n",
        "        \"img\": img_path,\n",
        "        \"segmask\": mask_path,\n",
        "        \"ID\": 0,\n",
        "        \"SIDE\": \"L\",\n",
        "        \"VISIT\": 0,\n",
        "        \"slice_idx\": idx,\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(samples)\n",
        "ds = KneeSegmentationDataset(df, val_trf)\n",
        "sample = ds[0]\n",
        "print(\"Image shape:\", sample[\"image\"].shape)\n",
        "print(\"Mask shape:\", sample[\"mask\"].shape)\n",
        "\n",
        "model = SimpleSegmentationNet(in_channels=3, num_classes=2).to(Cfg().device)\n",
        "with torch.no_grad():\n",
        "    logits = model(sample[\"image\"].unsqueeze(0).to(Cfg().device))\n",
        "print(\"Logits shape:\", logits.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop\n",
        "**Subtask:** Build a segmentation trainer loop (based on Assignment 3) with epoch-level logging for train/val loss and metrics.\n",
        "\n",
        "**Files modified:** `project/final_project.ipynb`\n",
        "\n",
        "**Sanity check:** Run a short training loop (few epochs) on the tiny synthetic dataset to confirm convergence behavior and logging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import sys\n",
        "\n",
        "\n",
        "class BaseTrainer:\n",
        "    def __init__(self, train_df, val_df, cfg):\n",
        "        self.train_df = train_df\n",
        "        self.val_df = val_df\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.train_loader = None\n",
        "        self.val_loader = None\n",
        "        self.loss_fn = None\n",
        "        self.optimizer = None\n",
        "        self.model = None\n",
        "\n",
        "    def init_model(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def init_run(self):\n",
        "        del self.train_loader\n",
        "        del self.val_loader\n",
        "        del self.optimizer\n",
        "\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        self.init_model()\n",
        "\n",
        "        train_ds = self.cfg.dataset_train_cls(\n",
        "            self.train_df,\n",
        "            self.cfg.train_trf,\n",
        "        )\n",
        "        val_ds = self.cfg.dataset_val_cls(\n",
        "            self.val_df,\n",
        "            self.cfg.val_trf,\n",
        "        )\n",
        "\n",
        "        self.train_loader = DataLoader(\n",
        "            train_ds,\n",
        "            batch_size=self.cfg.train_bs,\n",
        "            shuffle=True,\n",
        "            num_workers=self.cfg.n_workers,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "        self.val_loader = DataLoader(\n",
        "            val_ds,\n",
        "            batch_size=self.cfg.val_bs,\n",
        "            shuffle=False,\n",
        "            num_workers=self.cfg.n_workers,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "\n",
        "        self.optimizer = self.cfg.optimizer_cls(\n",
        "            self.model.parameters(),\n",
        "            lr=self.cfg.lr,\n",
        "            weight_decay=self.cfg.wd,\n",
        "        )\n",
        "        self.loss_fn = self.cfg.loss_fn\n",
        "\n",
        "    def adjust_lr(self):\n",
        "        if self.epoch in self.cfg.lr_drop_milestones:\n",
        "            for param_group in self.optimizer.param_groups:\n",
        "                param_group[\"lr\"] *= 0.1\n",
        "\n",
        "    def run(self, n_epochs=None):\n",
        "        self.init_run()\n",
        "        if n_epochs is None:\n",
        "            n_epochs = self.cfg.num_epochs\n",
        "        history = []\n",
        "        for self.epoch in range(n_epochs):\n",
        "            self.model.train()\n",
        "            train_loss = self.train_epoch()\n",
        "\n",
        "            self.model.eval()\n",
        "            val_out = self.val_epoch()\n",
        "            self.post_val_hook(train_loss, val_out)\n",
        "\n",
        "            history.append({\n",
        "                \"epoch\": self.epoch,\n",
        "                \"train_loss\": float(train_loss),\n",
        "                **val_out,\n",
        "            })\n",
        "        return history\n",
        "\n",
        "    def train_epoch(self):\n",
        "        sys.stderr.flush()\n",
        "        pbar = tqdm(total=len(self.train_loader), position=0, leave=True)\n",
        "        running_loss = 0.0\n",
        "\n",
        "        self.adjust_lr()\n",
        "\n",
        "        for i, batch in enumerate(self.train_loader):\n",
        "            self.optimizer.zero_grad()\n",
        "            loss, _ = self.pass_batch(batch)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            cur_loss = running_loss / (i + 1)\n",
        "\n",
        "            desc = f\"[{self.epoch}] Train {loss.item():.4f} / {cur_loss:.4f}\"\n",
        "            pbar.set_description(desc)\n",
        "            pbar.update()\n",
        "\n",
        "        pbar.close()\n",
        "        return running_loss / max(len(self.train_loader), 1)\n",
        "\n",
        "    def val_epoch(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def post_val_hook(self, train_loss, val_out):\n",
        "        sys.stderr.flush()\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"[{self.epoch}] --> Train loss : {train_loss:.4f}\")\n",
        "        print(f\"[{self.epoch}] --> Val loss   : {val_out['val_loss']:.4f}\")\n",
        "        if \"mean_iou\" in val_out:\n",
        "            print(f\"[{self.epoch}] --> Mean IoU   : {val_out['mean_iou']:.4f}\")\n",
        "        for cname in self.cfg.class_names:\n",
        "            key = f\"jaccard/{cname}\"\n",
        "            if key in val_out:\n",
        "                print(f\"    Jaccard [{cname}] : {val_out[key]:.4f}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "    def pass_batch(self, batch):\n",
        "        img = batch[\"image\"].to(self.cfg.device)\n",
        "        segmask = batch[\"mask\"].to(self.cfg.device)\n",
        "\n",
        "        logits = self.model(img)\n",
        "        target = segmask.squeeze(1).long()\n",
        "        loss = self.loss_fn(logits, target)\n",
        "\n",
        "        return loss, logits\n",
        "\n",
        "\n",
        "class SegmentationTrainer2D(BaseTrainer):\n",
        "    def init_model(self):\n",
        "        self.model = SimpleSegmentationNet(\n",
        "            in_channels=self.cfg.in_channels,\n",
        "            num_classes=self.cfg.num_classes,\n",
        "        ).to(self.cfg.device)\n",
        "\n",
        "    def compute_jaccard(self, logits, target):\n",
        "        if target.dim() == 4:\n",
        "            target = target.squeeze(1)\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        num_classes = len(self.cfg.class_names)\n",
        "        batch_size = preds.size(0)\n",
        "\n",
        "        results = []\n",
        "        for i in range(batch_size):\n",
        "            item_res = {}\n",
        "            p = preds[i]\n",
        "            t = target[i]\n",
        "\n",
        "            for c, cname in enumerate(self.cfg.class_names):\n",
        "                pred_c = (p == c)\n",
        "                true_c = (t == c)\n",
        "\n",
        "                inter = (pred_c & true_c).sum().float()\n",
        "                union = (pred_c | true_c).sum().float()\n",
        "\n",
        "                union_zero = (union == 0)\n",
        "                iou = torch.where(\n",
        "                    union_zero,\n",
        "                    torch.tensor(1.0, device=union.device),\n",
        "                    inter / (union + 1e-7),\n",
        "                )\n",
        "                item_res[cname] = iou.item()\n",
        "\n",
        "            results.append(item_res)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def val_epoch(self):\n",
        "        self.model.eval()\n",
        "        running_loss = 0.0\n",
        "        all_jaccards = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pbar = tqdm(total=len(self.val_loader), position=0, leave=False)\n",
        "\n",
        "            for i, batch in enumerate(self.val_loader):\n",
        "                img = batch[\"image\"].to(self.cfg.device)\n",
        "                mask = batch[\"mask\"].to(self.cfg.device)\n",
        "\n",
        "                logits = self.model(img)\n",
        "                target = mask.squeeze(1).long()\n",
        "                loss = self.loss_fn(logits, target)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                batch_jaccards = self.compute_jaccard(logits, mask)\n",
        "                all_jaccards.extend(batch_jaccards)\n",
        "\n",
        "                desc = f\"[{self.epoch}] Val {loss.item():.4f}\"\n",
        "                pbar.set_description(desc)\n",
        "                pbar.update()\n",
        "\n",
        "            pbar.close()\n",
        "\n",
        "        mean_val_loss = running_loss / max(len(self.val_loader), 1)\n",
        "\n",
        "        agg = {c: [] for c in self.cfg.class_names}\n",
        "        for entry in all_jaccards:\n",
        "            for cname, iou in entry.items():\n",
        "                agg[cname].append(iou)\n",
        "\n",
        "        mean_iou = {}\n",
        "        for cname in self.cfg.class_names:\n",
        "            mean_iou[cname] = float(np.mean(agg[cname])) if agg[cname] else 0.0\n",
        "\n",
        "        out = {\"val_loss\": mean_val_loss}\n",
        "        for cname, val in mean_iou.items():\n",
        "            out[f\"jaccard/{cname}\"] = val\n",
        "        out[\"mean_iou\"] = float(np.mean(list(mean_iou.values()))) if mean_iou else 0.0\n",
        "        return out\n",
        "\n",
        "\n",
        "cfg = Cfg()\n",
        "trainer = SegmentationTrainer2D(df, df, cfg)\n",
        "trainer.run(n_epochs=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation / Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Add prediction visualization and slice-wise evaluation helpers.\n",
        "# Example: overlay predictions on input slices or render scan-level summaries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset setup (Colab-ready)\n",
        "Define the data root and the volume-level index used to build the slice cache."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "DATA_ROOT = Path(os.environ.get(\"KNEE_DATA_ROOT\", \"/content/knee_data\"))\n",
        "VOLUME_CSV = DATA_ROOT / \"volumes.csv\"\n",
        "SLICE_CACHE_DIR = DATA_ROOT / \"slice_cache\"\n",
        "images_dir = SLICE_CACHE_DIR / \"images\"\n",
        "masks_dir = SLICE_CACHE_DIR / \"masks\"\n",
        "slice_index_path = SLICE_CACHE_DIR / \"slice_index.csv\"\n",
        "\n",
        "for d in [images_dir, masks_dir]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if not VOLUME_CSV.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Missing {VOLUME_CSV}. Expected a CSV with columns: ID, VISIT, SIDE, img, segmask.\"\n",
        "    )\n",
        "\n",
        "vol_df = pd.read_csv(VOLUME_CSV)\n",
        "required_cols = {\"ID\", \"VISIT\", \"SIDE\", \"img\", \"segmask\"}\n",
        "missing = required_cols - set(vol_df.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"volumes.csv missing columns: {sorted(missing)}\")\n",
        "\n",
        "print(f\"Loaded {len(vol_df)} volumes from {VOLUME_CSV}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7602396",
      "metadata": {},
      "source": [
        "## Subtask 1: Recreate slice caching and data indexing\n",
        "\n",
        "**Goal:** Convert 3D volumes into cached 2D slices and build a slice-level index.\n",
        "\n",
        "**Files modified/created:** `project/final_project.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2abaf238",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic imports\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import cv2\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Fixing one of the most annoying \"features\" of opencv\n",
        "cv2.ocl.setUseOpenCL(False)\n",
        "cv2.setNumThreads(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27ac3c87",
      "metadata": {},
      "outputs": [],
      "source": [
        "def vis_slice(img, lp=0, hp=99.9):\n",
        "    # Normalize a slice to uint8 for PNG storage.\n",
        "    img_float = img.astype(np.float32)\n",
        "    low = np.percentile(img_float, lp)\n",
        "    high = np.percentile(img_float, hp)\n",
        "    img_norm = (img_float - low) / (high - low)\n",
        "    img_norm = np.clip(img_norm, 0, 1)\n",
        "    return (img_norm * 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "def orient_slice(slice_2d):\n",
        "    # Match the orientation used in assignment 3 visualizations.\n",
        "    slice_2d = np.rot90(slice_2d, k=3)\n",
        "    slice_2d = np.fliplr(slice_2d)\n",
        "    return slice_2d\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78ddb04c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Slice caching + indexing (skip if cache already exists)\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "import multiprocessing as mp\n",
        "\n",
        "\n",
        "def process_volume(row_dict, images_dir, masks_dir):\n",
        "    row = pd.Series(row_dict)\n",
        "    img_nii = nib.load(row.img)\n",
        "    mask_nii = nib.load(row.segmask)\n",
        "\n",
        "    img_data = img_nii.get_fdata()\n",
        "    mask_data = mask_nii.get_fdata()\n",
        "\n",
        "    records = []\n",
        "    for slice_idx in range(img_data.shape[0]):\n",
        "        img_slice = orient_slice(vis_slice(img_data[slice_idx, :, :]))\n",
        "        mask_slice = orient_slice(mask_data[slice_idx, :, :])\n",
        "\n",
        "        img_name = f\"{row.ID}_{row.VISIT}_{row.SIDE}_slice{slice_idx:03d}.png\"\n",
        "        mask_name = f\"{row.ID}_{row.VISIT}_{row.SIDE}_slice{slice_idx:03d}.png\"\n",
        "        img_path = images_dir / img_name\n",
        "        mask_path = masks_dir / mask_name\n",
        "\n",
        "        cv2.imwrite(str(img_path), img_slice)\n",
        "        cv2.imwrite(str(mask_path), mask_slice.astype(np.uint8))\n",
        "\n",
        "        records.append({\n",
        "            \"ID\": row.ID,\n",
        "            \"VISIT\": row.VISIT,\n",
        "            \"SIDE\": row.SIDE,\n",
        "            \"slice_idx\": slice_idx,\n",
        "            \"img\": str(img_path),\n",
        "            \"segmask\": str(mask_path),\n",
        "        })\n",
        "\n",
        "    return records\n",
        "\n",
        "\n",
        "if slice_index_path.exists():\n",
        "    slice_ds = pd.read_csv(slice_index_path)\n",
        "else:\n",
        "    rows = vol_df.to_dict(orient=\"records\")\n",
        "    all_records = []\n",
        "    max_workers = min(4, mp.cpu_count())\n",
        "\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = [executor.submit(process_volume, row, images_dir, masks_dir) for row in rows]\n",
        "        for fut in as_completed(futures):\n",
        "            all_records.extend(fut.result())\n",
        "\n",
        "    slice_ds = pd.DataFrame(all_records)\n",
        "    slice_ds.to_csv(slice_index_path, index=False)\n",
        "\n",
        "slice_ds.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ef49aca",
      "metadata": {},
      "source": [
        "## Subtask 2: Patient-aware k-fold split logic\n",
        "\n",
        "**Goal:** Create patient-level folds without leakage and select a reference fold for downstream sanity checks.\n",
        "\n",
        "**Files modified/created:** `project/final_project.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b79046de",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_patient_folds(slice_df, n_splits=5, seed=SEED):\n",
        "    patients = slice_df[\"ID\"].astype(str) + \"_\" + slice_df[\"SIDE\"]\n",
        "    unique_patients = patients.unique()\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    shuffled = unique_patients.copy()\n",
        "    rng.shuffle(shuffled)\n",
        "\n",
        "    patient_folds = np.array_split(shuffled, n_splits)\n",
        "    folds = []\n",
        "    for fold_idx, val_patients in enumerate(patient_folds):\n",
        "        val_patients = set(val_patients.tolist())\n",
        "        train_patients = set(shuffled.tolist()) - val_patients\n",
        "\n",
        "        train_df = slice_df[patients.isin(train_patients)].reset_index(drop=True)\n",
        "        val_df = slice_df[patients.isin(val_patients)].reset_index(drop=True)\n",
        "\n",
        "        folds.append({\n",
        "            \"fold\": fold_idx,\n",
        "            \"train_df\": train_df,\n",
        "            \"val_df\": val_df,\n",
        "            \"train_patients\": train_patients,\n",
        "            \"val_patients\": val_patients,\n",
        "        })\n",
        "\n",
        "    return folds\n",
        "\n",
        "\n",
        "folds = make_patient_folds(slice_ds, n_splits=5)\n",
        "for fold in folds:\n",
        "    print(\n",
        "        f\"Fold {fold['fold']}: \"\n",
        "        f\"{len(fold['train_patients'])} train patients \u2192 {len(fold['train_df'])} slices, \"\n",
        "        f\"{len(fold['val_patients'])} val patients \u2192 {len(fold['val_df'])} slices\"\n",
        "    )\n",
        "\n",
        "reference_fold = folds[0]\n",
        "train_df = reference_fold[\"train_df\"]\n",
        "val_df = reference_fold[\"val_df\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bb9511b",
      "metadata": {},
      "source": [
        "### Sanity check 2\n",
        "Ensure each fold has disjoint train/val patients and all patients are covered.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83cea61d",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_patients = set()\n",
        "for fold in folds:\n",
        "    train_patients = fold[\"train_patients\"]\n",
        "    val_patients = fold[\"val_patients\"]\n",
        "    assert train_patients.isdisjoint(val_patients), \"Train/val leakage in fold.\"\n",
        "    all_patients.update(train_patients)\n",
        "    all_patients.update(val_patients)\n",
        "\n",
        "unique_patients = set((slice_ds[\"ID\"].astype(str) + \"_\" + slice_ds[\"SIDE\"]).unique())\n",
        "assert all_patients == unique_patients, \"Not all patients are covered by folds.\"\n",
        "\n",
        "print(\"All folds are disjoint and cover the full patient set.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subtask 3: K-fold training/evaluation loop\n",
        "\n",
        "**Goal:** Train and evaluate the model across folds, logging per-fold metrics and aggregate mean/std.\n",
        "\n",
        "**Files modified/created:** `project/final_project.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def run_cross_validation(folds, cfg):\n",
        "    fold_metrics = []\n",
        "    for fold in folds:\n",
        "        print(f\"\\n=== Fold {fold['fold'] + 1}/{len(folds)} ===\")\n",
        "        trainer = SegmentationTrainer2D(fold[\"train_df\"], fold[\"val_df\"], cfg)\n",
        "        history = trainer.run(n_epochs=cfg.num_epochs)\n",
        "        last_metrics = history[-1] if history else {}\n",
        "        fold_result = {\"fold\": fold[\"fold\"], **last_metrics}\n",
        "        fold_metrics.append(fold_result)\n",
        "        print({k: v for k, v in fold_result.items() if k != \"fold\"})\n",
        "\n",
        "    metrics_df = pd.DataFrame(fold_metrics)\n",
        "    metric_cols = [c for c in metrics_df.columns if c not in {\"fold\", \"epoch\"}]\n",
        "    summary = {}\n",
        "    for col in metric_cols:\n",
        "        values = metrics_df[col].dropna().astype(float)\n",
        "        if len(values) > 0:\n",
        "            summary[col] = {\n",
        "                \"mean\": float(values.mean()),\n",
        "                \"std\": float(values.std(ddof=0)),\n",
        "            }\n",
        "\n",
        "    return metrics_df, summary\n",
        "\n",
        "\n",
        "cv_cfg = Cfg()\n",
        "fold_metrics_df, cv_summary = run_cross_validation(folds, cv_cfg)\n",
        "print(\"\\nPer-fold metrics:\")\n",
        "display(fold_metrics_df)\n",
        "print(\"\\nAggregate metrics (mean/std):\")\n",
        "display(pd.DataFrame(cv_summary).T)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac8557c6",
      "metadata": {},
      "source": [
        "## Subtask 4: Minimal batch sanity check\n",
        "\n",
        "**Goal:** Load a batch and confirm shapes + mask alignment.\n",
        "\n",
        "**Files modified/created:** `project/final_project.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "871cc2ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class SliceDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = cv2.imread(row.img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(row.segmask, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0\n",
        "        mask = torch.from_numpy(mask).long()\n",
        "        return {\"image\": img, \"mask\": mask}\n",
        "\n",
        "\n",
        "train_ds = SliceDataset(train_df)\n",
        "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0)\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "images = batch[\"image\"]\n",
        "masks = batch[\"mask\"]\n",
        "\n",
        "print(\"Image batch shape:\", images.shape)\n",
        "print(\"Mask batch shape:\", masks.shape)\n",
        "assert images.shape[-2:] == masks.shape[-2:], \"Image/mask spatial dimensions do not match.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b680980c",
      "metadata": {},
      "source": [
        "### Sanity check 3\n",
        "Visualize a single image/mask pair for alignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65a7f4e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "img_np = images[0].permute(1, 2, 0).numpy()\n",
        "mask_np = masks[0].numpy()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
        "axes[0].imshow(img_np)\n",
        "axes[0].set_title(\"Image\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(mask_np, cmap=\"viridis\")\n",
        "axes[1].set_title(\"Mask\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subtask 5: Signed distance field targets\n",
        "\n",
        "**Goal:** Convert each 2D hard mask slice into a signed distance field (inside negative, outside positive) with stable normalization/clipping.\n",
        "\n",
        "**Files modified/created:** `project/final_project.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def hard_mask_to_sdf(mask, clip_value=20.0, normalize=True, eps=1e-6):\n",
        "    \"\"\"Convert a 2D hard mask into a signed distance field.\n",
        "\n",
        "    Inside the mask is negative, outside is positive.\n",
        "    \"\"\"\n",
        "    if torch.is_tensor(mask):\n",
        "        mask_np = mask.detach().cpu().numpy()\n",
        "    else:\n",
        "        mask_np = np.asarray(mask)\n",
        "\n",
        "    if mask_np.ndim == 3 and mask_np.shape[0] == 1:\n",
        "        mask_np = mask_np[0]\n",
        "\n",
        "    mask_bin = (mask_np > 0).astype(np.uint8)\n",
        "    dist_out = cv2.distanceTransform(1 - mask_bin, cv2.DIST_L2, 5)\n",
        "    dist_in = cv2.distanceTransform(mask_bin, cv2.DIST_L2, 5)\n",
        "    sdf = dist_out - dist_in\n",
        "\n",
        "    if clip_value is not None:\n",
        "        sdf = np.clip(sdf, -clip_value, clip_value)\n",
        "    if normalize:\n",
        "        denom = np.max(np.abs(sdf)) + eps\n",
        "        sdf = sdf / denom\n",
        "\n",
        "    return sdf.astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sanity check 4\n",
        "Visualize SDFs for a few slices and confirm boundary values are near zero.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def boundary_mask(binary_mask, kernel_size=3):\n",
        "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
        "    eroded = cv2.erode(binary_mask.astype(np.uint8), kernel, iterations=1)\n",
        "    return (binary_mask.astype(np.uint8) - eroded).astype(bool)\n",
        "\n",
        "\n",
        "num_slices = min(3, masks.shape[0])\n",
        "fig, axes = plt.subplots(num_slices, 3, figsize=(9, 3 * num_slices))\n",
        "if num_slices == 1:\n",
        "    axes = np.expand_dims(axes, axis=0)\n",
        "\n",
        "for i in range(num_slices):\n",
        "    img_np = images[i].permute(1, 2, 0).numpy()\n",
        "    mask_np = masks[i].numpy()\n",
        "\n",
        "    sdf = hard_mask_to_sdf(mask_np, clip_value=20.0, normalize=True)\n",
        "\n",
        "    axes[i, 0].imshow(img_np)\n",
        "    axes[i, 0].set_title(f\"Image {i}\")\n",
        "    axes[i, 0].axis(\"off\")\n",
        "\n",
        "    axes[i, 1].imshow(mask_np, cmap=\"gray\")\n",
        "    axes[i, 1].set_title(\"Mask\")\n",
        "    axes[i, 1].axis(\"off\")\n",
        "\n",
        "    im = axes[i, 2].imshow(sdf, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
        "    axes[i, 2].set_title(\"SDF (normalized)\")\n",
        "    axes[i, 2].axis(\"off\")\n",
        "\n",
        "    boundary = boundary_mask(mask_np > 0)\n",
        "    boundary_mean = np.mean(np.abs(sdf[boundary])) if boundary.any() else np.nan\n",
        "    print(f\"Slice {i}: SDF min={sdf.min():.3f}, max={sdf.max():.3f}, boundary mean |sdf|={boundary_mean:.3f}\")\n",
        "    assert boundary_mean < 0.2, \"Boundary is not close to zero after normalization.\"\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subtask 6: Losses and metrics\n",
        "\n",
        "**Goal:** Define primary L1 loss and evaluation metrics for SDF regression.\n",
        "\n",
        "**Files modified/created:** `project/final_project.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def l1_loss(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Primary L1 loss for SDF regression.\"\"\"\n",
        "    return F.l1_loss(pred, target)\n",
        "\n",
        "\n",
        "def sdf_mae(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.mean(torch.abs(pred - target))\n",
        "\n",
        "\n",
        "def sdf_rmse(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "\n",
        "def sdf_to_mask(sdf: torch.Tensor, thresh: float = 0.0) -> torch.Tensor:\n",
        "    return sdf < thresh\n",
        "\n",
        "\n",
        "def dice_iou_from_sdf(\n",
        "    pred_sdf: torch.Tensor,\n",
        "    target_sdf: torch.Tensor,\n",
        "    thresh: float = 0.0,\n",
        "    eps: float = 1e-6,\n",
        ") -> dict:\n",
        "    pred_mask = sdf_to_mask(pred_sdf, thresh=thresh)\n",
        "    target_mask = sdf_to_mask(target_sdf, thresh=thresh)\n",
        "\n",
        "    intersection = (pred_mask & target_mask).sum().float()\n",
        "    pred_sum = pred_mask.sum().float()\n",
        "    target_sum = target_mask.sum().float()\n",
        "    union = pred_sum + target_sum - intersection\n",
        "\n",
        "    dice = (2 * intersection + eps) / (pred_sum + target_sum + eps)\n",
        "    iou = (intersection + eps) / (union + eps)\n",
        "    return {\"dice\": dice, \"iou\": iou}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subtask 7: Tiny overfit sanity check\n",
        "\n",
        "**Goal:** Overfit a single slice with INR + L1 loss to verify loss decreases.\n",
        "\n",
        "**Files modified/created:** `project/final_project.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "device = Cfg().device\n",
        "slice_mask = masks[0].numpy()\n",
        "sdf_target_np = hard_mask_to_sdf(slice_mask, clip_value=20.0, normalize=True)\n",
        "sdf_target = torch.from_numpy(sdf_target_np).to(device)\n",
        "\n",
        "height, width = sdf_target.shape\n",
        "ys = torch.linspace(-1, 1, steps=height, device=device)\n",
        "xs = torch.linspace(-1, 1, steps=width, device=device)\n",
        "grid_y, grid_x = torch.meshgrid(ys, xs, indexing=\"ij\")\n",
        "coords = torch.stack([grid_x, grid_y], dim=-1)\n",
        "\n",
        "inr = INRMLP(in_features=2, hidden_features=64, hidden_layers=3, out_features=1).to(device)\n",
        "optimizer = torch.optim.Adam(inr.parameters(), lr=1e-3)\n",
        "loss_fn = torch.nn.L1Loss()\n",
        "\n",
        "loss_history = []\n",
        "for step in range(60):\n",
        "    optimizer.zero_grad()\n",
        "    pred = inr(coords)\n",
        "    loss = loss_fn(pred, sdf_target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_history.append(loss.item())\n",
        "\n",
        "print(f\"Overfit loss: start={loss_history[0]:.4f}, end={loss_history[-1]:.4f}\")\n",
        "assert loss_history[-1] < loss_history[0], \"Overfit sanity check failed: loss did not decrease.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subtask 8: Baseline vs. SDF regression comparison\n",
        "\n",
        "**Goal:** Train a hard-mask baseline and an SDF regression model with identical splits/preprocessing, then log metrics and produce plots/tables for the report.\n",
        "\n",
        "**Files modified/created:** `project/final_project.ipynb`\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@dataclass\n",
        "class CfgSDFRegression(Cfg):\n",
        "    \"\"\"Configuration for SDF regression with a single-channel output.\"\"\"\n",
        "\n",
        "    num_classes: int = 1\n",
        "    loss_fn = l1_loss\n",
        "    class_names: list[str] | None = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.lr_drop_milestones is None:\n",
        "            self.lr_drop_milestones = [30]\n",
        "        if self.class_names is None:\n",
        "            self.class_names = [\"BG\", \"FG\"]\n",
        "        self.num_classes = 1\n",
        "\n",
        "\n",
        "def batch_masks_to_sdf(mask_batch, clip_value=20.0, normalize=True):\n",
        "    sdf_list = []\n",
        "    mask_np = mask_batch.detach().cpu().numpy()\n",
        "    for i in range(mask_np.shape[0]):\n",
        "        sdf = hard_mask_to_sdf(mask_np[i], clip_value=clip_value, normalize=normalize)\n",
        "        sdf_list.append(sdf)\n",
        "    sdf_stack = np.stack(sdf_list, axis=0)\n",
        "    return torch.from_numpy(sdf_stack).to(mask_batch.device).float()\n",
        "\n",
        "\n",
        "def binary_iou(pred_mask: torch.Tensor, true_mask: torch.Tensor) -> dict:\n",
        "    pred_mask = pred_mask.bool()\n",
        "    true_mask = true_mask.bool()\n",
        "\n",
        "    def _iou(pred, true):\n",
        "        inter = (pred & true).sum().float()\n",
        "        union = (pred | true).sum().float()\n",
        "        return torch.where(union == 0, torch.tensor(1.0, device=union.device), inter / (union + 1e-7))\n",
        "\n",
        "    iou_fg = _iou(pred_mask, true_mask)\n",
        "    iou_bg = _iou(~pred_mask, ~true_mask)\n",
        "    return {\"BG\": iou_bg.item(), \"FG\": iou_fg.item()}\n",
        "\n",
        "\n",
        "class SDFRegressionTrainer(BaseTrainer):\n",
        "    def init_model(self):\n",
        "        self.model = SimpleSegmentationNet(\n",
        "            in_channels=self.cfg.in_channels,\n",
        "            num_classes=self.cfg.num_classes,\n",
        "        ).to(self.cfg.device)\n",
        "\n",
        "    def pass_batch(self, batch):\n",
        "        img = batch[\"image\"].to(self.cfg.device)\n",
        "        mask = batch[\"mask\"].to(self.cfg.device)\n",
        "\n",
        "        pred = self.model(img).squeeze(1)\n",
        "        sdf_target = batch_masks_to_sdf(mask, clip_value=20.0, normalize=True)\n",
        "        loss = self.loss_fn(pred, sdf_target)\n",
        "        return loss, pred\n",
        "\n",
        "    def val_epoch(self):\n",
        "        self.model.eval()\n",
        "        running_loss = 0.0\n",
        "        all_ious = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pbar = tqdm(total=len(self.val_loader), position=0, leave=False)\n",
        "            for batch in self.val_loader:\n",
        "                img = batch[\"image\"].to(self.cfg.device)\n",
        "                mask = batch[\"mask\"].to(self.cfg.device)\n",
        "\n",
        "                pred = self.model(img).squeeze(1)\n",
        "                sdf_target = batch_masks_to_sdf(mask, clip_value=20.0, normalize=True)\n",
        "                loss = self.loss_fn(pred, sdf_target)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                pred_mask = pred <= 0\n",
        "                true_mask = mask.squeeze(1) > 0\n",
        "                for i in range(pred_mask.shape[0]):\n",
        "                    all_ious.append(binary_iou(pred_mask[i], true_mask[i]))\n",
        "\n",
        "                pbar.set_description(f\"[{self.epoch}] Val {loss.item():.4f}\")\n",
        "                pbar.update()\n",
        "\n",
        "            pbar.close()\n",
        "\n",
        "        mean_val_loss = running_loss / max(len(self.val_loader), 1)\n",
        "        agg = {c: [] for c in self.cfg.class_names}\n",
        "        for entry in all_ious:\n",
        "            for cname, iou in entry.items():\n",
        "                agg[cname].append(iou)\n",
        "\n",
        "        mean_iou = {c: float(np.mean(agg[c])) if agg[c] else 0.0 for c in self.cfg.class_names}\n",
        "        out = {\"val_loss\": mean_val_loss}\n",
        "        for cname, val in mean_iou.items():\n",
        "            out[f\"jaccard/{cname}\"] = val\n",
        "        out[\"mean_iou\"] = float(np.mean(list(mean_iou.values()))) if mean_iou else 0.0\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### INR regression trainer\n",
        "Uses the coordinate-based INR to regress SDF values per slice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class CfgINRRegression(Cfg):\n",
        "    num_classes: int = 1\n",
        "    loss_fn = l1_loss\n",
        "    class_names: list[str] | None = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.lr_drop_milestones is None:\n",
        "            self.lr_drop_milestones = [30]\n",
        "        if self.class_names is None:\n",
        "            self.class_names = [\"BG\", \"FG\"]\n",
        "        self.num_classes = 1\n",
        "\n",
        "\n",
        "class INRRegressionTrainer(BaseTrainer):\n",
        "    def __init__(self, train_df: pd.DataFrame, val_df: pd.DataFrame, cfg: Cfg):\n",
        "        super().__init__(train_df, val_df, cfg)\n",
        "        self._coord_cache = None\n",
        "\n",
        "    def init_model(self):\n",
        "        self.model = INRMLP(in_features=2, hidden_features=128, hidden_layers=4, out_features=1).to(self.cfg.device)\n",
        "\n",
        "    def _get_coords(self, height: int, width: int, device: torch.device) -> torch.Tensor:\n",
        "        if self._coord_cache is None or self._coord_cache.shape[:2] != (height, width):\n",
        "            ys = torch.linspace(-1, 1, steps=height, device=device)\n",
        "            xs = torch.linspace(-1, 1, steps=width, device=device)\n",
        "            grid_y, grid_x = torch.meshgrid(ys, xs, indexing=\"ij\")\n",
        "            self._coord_cache = torch.stack([grid_x, grid_y], dim=-1)\n",
        "        return self._coord_cache\n",
        "\n",
        "    def pass_batch(self, batch):\n",
        "        mask = batch[\"mask\"].to(self.cfg.device)\n",
        "        sdf_target = batch_masks_to_sdf(mask, clip_value=20.0, normalize=True)\n",
        "\n",
        "        height, width = sdf_target.shape[-2:]\n",
        "        coords = self._get_coords(height, width, self.cfg.device)\n",
        "        pred = self.model(coords).unsqueeze(0).expand(sdf_target.shape[0], -1, -1)\n",
        "        loss = self.loss_fn(pred, sdf_target)\n",
        "        return loss, pred\n",
        "\n",
        "    def val_epoch(self):\n",
        "        self.model.eval()\n",
        "        running_loss = 0.0\n",
        "        all_ious = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pbar = tqdm(total=len(self.val_loader), position=0, leave=False)\n",
        "            for batch in self.val_loader:\n",
        "                mask = batch[\"mask\"].to(self.cfg.device)\n",
        "                sdf_target = batch_masks_to_sdf(mask, clip_value=20.0, normalize=True)\n",
        "\n",
        "                height, width = sdf_target.shape[-2:]\n",
        "                coords = self._get_coords(height, width, self.cfg.device)\n",
        "                pred = self.model(coords).unsqueeze(0).expand(sdf_target.shape[0], -1, -1)\n",
        "                loss = self.loss_fn(pred, sdf_target)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                pred_mask = pred <= 0\n",
        "                true_mask = mask.squeeze(1) > 0\n",
        "                for i in range(pred_mask.shape[0]):\n",
        "                    all_ious.append(binary_iou(pred_mask[i], true_mask[i]))\n",
        "\n",
        "                pbar.set_description(f\"[{self.epoch}] Val {loss.item():.4f}\")\n",
        "                pbar.update()\n",
        "\n",
        "            pbar.close()\n",
        "\n",
        "        mean_val_loss = running_loss / max(len(self.val_loader), 1)\n",
        "        agg = {c: [] for c in self.cfg.class_names}\n",
        "        for entry in all_ious:\n",
        "            for cname, iou in entry.items():\n",
        "                agg[cname].append(iou)\n",
        "\n",
        "        mean_iou = {c: float(np.mean(agg[c])) if agg[c] else 0.0 for c in self.cfg.class_names}\n",
        "        out = {\"val_loss\": mean_val_loss}\n",
        "        for cname, val in mean_iou.items():\n",
        "            out[f\"jaccard/{cname}\"] = val\n",
        "        out[\"mean_iou\"] = float(np.mean(list(mean_iou.values()))) if mean_iou else 0.0\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def run_baseline_vs_sdf(folds, baseline_cfg, sdf_cfg):\n",
        "    rows = []\n",
        "    for fold in folds:\n",
        "        print(f\"\\n=== Fold {fold['fold'] + 1}/{len(folds)} ===\")\n",
        "        baseline_trainer = SegmentationTrainer2D(fold[\"train_df\"], fold[\"val_df\"], baseline_cfg)\n",
        "        baseline_hist = baseline_trainer.run(n_epochs=baseline_cfg.num_epochs)\n",
        "        baseline_metrics = baseline_hist[-1] if baseline_hist else {}\n",
        "        rows.append({\"fold\": fold[\"fold\"], \"method\": \"hard_mask\", **baseline_metrics})\n",
        "\n",
        "        sdf_trainer = SDFRegressionTrainer(fold[\"train_df\"], fold[\"val_df\"], sdf_cfg)\n",
        "        sdf_hist = sdf_trainer.run(n_epochs=sdf_cfg.num_epochs)\n",
        "        sdf_metrics = sdf_hist[-1] if sdf_hist else {}\n",
        "        rows.append({\"fold\": fold[\"fold\"], \"method\": \"sdf_regression\", **sdf_metrics})\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "def summarize_comparison(df: pd.DataFrame):\n",
        "    metric_cols = [col for col in df.columns if col not in [\"fold\", \"method\", \"epoch\"]]\n",
        "    summary = df.groupby(\"method\")[metric_cols].agg([\"mean\", \"std\"])\n",
        "    return summary\n",
        "\n",
        "\n",
        "def plot_comparison(summary_df, out_path):\n",
        "    metrics = [\"mean_iou\", \"jaccard/FG\", \"val_loss\"]\n",
        "    fig, axes = plt.subplots(1, len(metrics), figsize=(4 * len(metrics), 4))\n",
        "    if len(metrics) == 1:\n",
        "        axes = [axes]\n",
        "    for ax, metric in zip(axes, metrics):\n",
        "        if (metric, \"mean\") not in summary_df.columns:\n",
        "            ax.axis(\"off\")\n",
        "            continue\n",
        "        means = summary_df[(metric, \"mean\")]\n",
        "        stds = summary_df[(metric, \"std\")]\n",
        "        means.plot(kind=\"bar\", yerr=stds, ax=ax, capsize=4)\n",
        "        ax.set_title(metric)\n",
        "        ax.set_xlabel(\"Method\")\n",
        "        ax.set_ylabel(metric)\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(out_path, dpi=150)\n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sanity check 5\n",
        "Run a tiny baseline + SDF regression comparison on a small slice subset to confirm metrics logging.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "quick_train_df = reference_fold[\"train_df\"].head(10).reset_index(drop=True)\n",
        "quick_val_df = reference_fold[\"val_df\"].head(10).reset_index(drop=True)\n",
        "quick_folds = [{\"fold\": 0, \"train_df\": quick_train_df, \"val_df\": quick_val_df}]\n",
        "\n",
        "baseline_cfg = Cfg(num_epochs=1, train_bs=2, val_bs=2)\n",
        "sdf_cfg = CfgSDFRegression(num_epochs=1, train_bs=2, val_bs=2)\n",
        "inr_cfg = CfgINRRegression(num_epochs=1, train_bs=2, val_bs=2)\n",
        "\n",
        "sanity_rows = []\n",
        "sanity_rows.append(run_baseline_vs_sdf(quick_folds, baseline_cfg, sdf_cfg))\n",
        "inr_trainer = INRRegressionTrainer(quick_train_df, quick_val_df, inr_cfg)\n",
        "inr_hist = inr_trainer.run(n_epochs=inr_cfg.num_epochs)\n",
        "inr_metrics = inr_hist[-1] if inr_hist else {}\n",
        "sanity_rows.append(pd.DataFrame([{\"fold\": 0, \"method\": \"inr_regression\", **inr_metrics}]))\n",
        "\n",
        "sanity_df = pd.concat(sanity_rows, ignore_index=True)\n",
        "display(sanity_df)\n",
        "\n",
        "summary = summarize_comparison(sanity_df)\n",
        "display(summary)\n",
        "\n",
        "if (\"mean_iou\", \"mean\") in summary.columns:\n",
        "    baseline_iou = summary.loc[\"hard_mask\", (\"mean_iou\", \"mean\")] if \"hard_mask\" in summary.index else None\n",
        "    sdf_iou = summary.loc[\"sdf_regression\", (\"mean_iou\", \"mean\")] if \"sdf_regression\" in summary.index else None\n",
        "    inr_iou = summary.loc[\"inr_regression\", (\"mean_iou\", \"mean\")] if \"inr_regression\" in summary.index else None\n",
        "    print(f\"Baseline mean IoU: {baseline_iou}\")\n",
        "    print(f\"SDF mean IoU: {sdf_iou}\")\n",
        "    print(f\"INR mean IoU: {inr_iou}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Full baseline vs. SDF regression comparison (report-ready artifacts)\n",
        "Set the epoch counts below to your desired training length. This section logs fold-level metrics,\n",
        "computes mean \u00b1 std tables, and saves plots/tables for the report.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "RUN_FULL_COMPARISON = False  # flip to True when ready for full experiments\n",
        "BASELINE_EPOCHS = 10\n",
        "SDF_EPOCHS = 10\n",
        "\n",
        "if RUN_FULL_COMPARISON:\n",
        "    baseline_cfg = Cfg(num_epochs=BASELINE_EPOCHS, train_bs=2, val_bs=2)\n",
        "    sdf_cfg = CfgSDFRegression(num_epochs=SDF_EPOCHS, train_bs=2, val_bs=2)\n",
        "\n",
        "    comparison_df = run_baseline_vs_sdf(folds, baseline_cfg, sdf_cfg)\n",
        "    summary_df = summarize_comparison(comparison_df)\n",
        "\n",
        "    artifacts_dir = Path(\"project/artifacts\")\n",
        "    artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    comparison_csv = artifacts_dir / \"baseline_vs_sdf_folds.csv\"\n",
        "    summary_csv = artifacts_dir / \"baseline_vs_sdf_summary.csv\"\n",
        "    summary_md = artifacts_dir / \"baseline_vs_sdf_summary.md\"\n",
        "    plot_path = artifacts_dir / \"baseline_vs_sdf_metrics.png\"\n",
        "\n",
        "    comparison_df.to_csv(comparison_csv, index=False)\n",
        "    summary_df.to_csv(summary_csv)\n",
        "    summary_df.to_markdown(summary_md)\n",
        "\n",
        "    plot_comparison(summary_df, plot_path)\n",
        "    display(comparison_df)\n",
        "    display(summary_df)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}